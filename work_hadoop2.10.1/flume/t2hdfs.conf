# 给a1的sources、sinks、channels定义名称(自定义)
a1.sources = r1
a1.sinks = s1
a1.channels = c1



# 设置数据源类型
a1.sources.r1.type = netcat
# 设置数据源绑定的 IP
a1.sources.r1.bind = localhost
# 设置数据源监听的端口
a1.sources.r1.port = 44444




# 设置采集的数据类型为hdfs
a1.sinks.s1.type=hdfs
a1.sinks.s1.hdfs.path=hdfs://lookmaster:9000/flume1
a1.sinks.s1.hdfs.fileType=DataStream
#在实际生产中要非常注意这三个值的设定，一定要避免生成的文件不要太小，否则hadoop的性能发挥不出来
#单位是秒，如果设置为0，表示该配置不生效
a1.sinks.s1.rollInterval=600
#单位是字节，如果设置为0，表示该配置不生效
a1.sinks.s1.rollSize=10240
#记录行数，如果设置为0，表示该配置不生效
a1.sinks.s1.rollCount=100




# 设置管道类型为memory内存
a1.channels.c1.type = memory
# 设置管道容量大小
a1.channels.c1.capacity = 1000
# 设置管道吞吐量大小
a1.channels.c1.transactionCapacity = 100





# 将source和sink绑定到channel上
a1.sources.r1.channels = c1
a1.sinks.s1.channel = c1



